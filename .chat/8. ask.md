用Pytorch编写一个TransformerModel

下方这个模型为什么和上方的示例差别比较大？
class TransformerModel(nn.Module):
    def __init__(self, input_size, d_model, nhead, num_layers, output_size):
        """
        初始化 Transformer 模型。
        :param input_size: 输入特征的维度
        :param d_model: Transformer 模型的隐藏层维度
        :param nhead: 多头注意力机制的头数
        :param num_layers: Transformer 编码器的层数
        :param output_size: 输出动作的维度
        """
        super(TransformerModel, self).__init__()
        self.embedding = nn.Linear(input_size, d_model)  # 输入嵌入层
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model, nhead, norm_first=True),  # 层归一化在前
            num_layers
        )
        self.fc = nn.Linear(d_model, output_size)  # 输出层

    def forward(self, x):
        """
        前向传播。
        :param x: 输入状态
        :return: 输出动作值
        """
        x = self.embedding(x)  # 嵌入输入
        x = x.permute(1, 0, 2)  # 调整维度以适应 Transformer 的输入格式 [batch_size, sequence_length, d_model]
        x = self.transformer_encoder(x)  # 通过 Transformer 编码器
        # 对每个时间步的特征进行全连接层处理
        batch_size, sequence_length, d_model = x.shape
        x = x.view(-1, d_model)  # 合并批量和序列长度维度
        x = self.fc(x)
        x = x.view(batch_size, sequence_length, -1)  # 恢复形状为 [batch_size, sequence_length, output_size]
        return x